# GenAI Supply Chain â€” Forecasting â†’ Inventory Policy â†’ Simulator â†’ App

**Akhila Madanapati** â€¢ Repo: `am3469/genai-scm`  
Turn raw retail data into **forecasts**, **reorder policies (ROP / Target-S / EOQ)**, a **scenario simulator** (lead-time Ã—, demand spikes, supplier outages), and a **Streamlit dashboard** for decisions.

## Why this is interesting
- Business KPIs: **fill rate, stockout days, orders, avg on-hand**
- Practical constraints: **lead times, MOQ, supplier mapping**
- Clear pipeline: **ETL â†’ backtest â†’ policy â†’ simulate â†’ app**

---

## ðŸ”§ Quickstart

```bash
# 1) environment
conda create -n genai-scm python=3.11 -y
conda activate genai-scm
pip install -r requirements.txt

# 2) place your raw file
# data/raw/retail.csv   (CSV or Parquet)

# 3) ETL â†’ standardized daily tables (+ optional SQLite)
python -m src.etl.prepare --raw data/raw/retail.csv --out data/processed --make-db

# 4) forecasts + validation metrics (WAPE, sMAPE)
python -m src.forecast.backtest --sales data/processed/sales_daily.csv --horizon 28 --top_k_skus 10

# 5) inventory policy (ROP / Target-S / EOQ) with safety stock & MOQ
python -m src.optimize.policy \
  --sales data/processed/sales_daily.csv \
  --inventory data/processed/inventory_daily.csv \
  --suppliers data/processed/suppliers.csv \
  --forecasts models/forecasts.csv \
  --service 0.95 --cycle_days 7 --horizon 28 --outdir data/processed

# 6) simulator (baseline & scenarios)
python -m src.risk.simulate \
  --sales data/processed/sales_daily.csv \
  --inventory data/processed/inventory_daily.csv \
  --suppliers data/processed/suppliers.csv \
  --policy data/processed/policy_recs.csv \
  --horizon 28

# example stress test
python -m src.risk.simulate \
  --sales data/processed/sales_daily.csv \
  --inventory data/processed/inventory_daily.csv \
  --suppliers data/processed/suppliers.csv \
  --policy data/processed/policy_recs.csv \
  --horizon 28 --lead_mult 1.5 --demand_spike 0.2 --supplier_outage "S007"

# 7) dashboard
streamlit run src/app/app.py

Architecture
flowchart LR
  A[Raw data: data/raw] --> B[ETL: src/etl/prepare.py]
  B --> C[Processed tables: data/processed/*]
  C --> D[Backtest: src/forecast/backtest.py]
  D --> E[Forecasts: models/forecasts.*]
  C --> F[Policy: src/optimize/policy.py]
  E --> F
  F --> G[Simulator: src/risk/simulate.py]
  G --> H[Streamlit App: src/app/app.py]

Repository Structure
.
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ app/        # Streamlit (app.py)
â”‚   â”œâ”€â”€ etl/        # prepare.py (schema + standardization)
â”‚   â”œâ”€â”€ forecast/   # backtest.py (baselines + metrics)
â”‚   â”œâ”€â”€ optimize/   # policy.py (ROP/Target-S/EOQ, safety stock, MOQ)
â”‚   â””â”€â”€ risk/       # simulate.py (scenario engine + KPIs)
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ raw/        # put retail.csv here (gitignored)
â”‚   â””â”€â”€ processed/  # ETL outputs, policy, sim outputs (gitignored)
â”œâ”€â”€ models/         # forecasts (gitignored)
â”œâ”€â”€ reports/        # metrics (WAPE/sMAPE)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ Makefile


Tech Stack
Python 3.11, Pandas, NumPy, scikit-learn, XGBoost, Streamlit, Pydantic, PyArrow, SQLAlchemy.
